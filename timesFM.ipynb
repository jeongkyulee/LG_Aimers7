{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /opt/anaconda3/envs/timesfm311/lib/python3.11/site-packages (2.8.0)\n",
      "Collecting timesfm[torch]\n",
      "  Using cached timesfm-1.3.0-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: absl-py>=1.4.0 in /opt/anaconda3/envs/timesfm311/lib/python3.11/site-packages (from timesfm[torch]) (2.3.1)\n",
      "Requirement already satisfied: einshape>=1.0.0 in /opt/anaconda3/envs/timesfm311/lib/python3.11/site-packages (from timesfm[torch]) (1.0)\n",
      "Requirement already satisfied: huggingface_hub>=0.23.0 in /opt/anaconda3/envs/timesfm311/lib/python3.11/site-packages (from huggingface_hub[cli]>=0.23.0->timesfm[torch]) (0.34.4)\n",
      "Requirement already satisfied: numpy>=1.26.4 in /opt/anaconda3/envs/timesfm311/lib/python3.11/site-packages (from timesfm[torch]) (2.3.2)\n",
      "Requirement already satisfied: pandas>=2.0.0 in /opt/anaconda3/envs/timesfm311/lib/python3.11/site-packages (from timesfm[torch]) (2.3.1)\n",
      "Requirement already satisfied: scikit-learn>=1.2.2 in /opt/anaconda3/envs/timesfm311/lib/python3.11/site-packages (from timesfm[torch]) (1.7.1)\n",
      "Requirement already satisfied: typer>=0.12.3 in /opt/anaconda3/envs/timesfm311/lib/python3.11/site-packages (from timesfm[torch]) (0.16.0)\n",
      "Requirement already satisfied: utilsforecast>=0.1.10 in /opt/anaconda3/envs/timesfm311/lib/python3.11/site-packages (from timesfm[torch]) (0.2.12)\n",
      "Requirement already satisfied: wandb>=0.17.5 in /opt/anaconda3/envs/timesfm311/lib/python3.11/site-packages (from timesfm[torch]) (0.21.1)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/envs/timesfm311/lib/python3.11/site-packages (from torch) (3.19.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /opt/anaconda3/envs/timesfm311/lib/python3.11/site-packages (from torch) (4.14.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /opt/anaconda3/envs/timesfm311/lib/python3.11/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/envs/timesfm311/lib/python3.11/site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/envs/timesfm311/lib/python3.11/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /opt/anaconda3/envs/timesfm311/lib/python3.11/site-packages (from torch) (2025.7.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/anaconda3/envs/timesfm311/lib/python3.11/site-packages (from huggingface_hub>=0.23.0->huggingface_hub[cli]>=0.23.0->timesfm[torch]) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/envs/timesfm311/lib/python3.11/site-packages (from huggingface_hub>=0.23.0->huggingface_hub[cli]>=0.23.0->timesfm[torch]) (6.0.2)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/envs/timesfm311/lib/python3.11/site-packages (from huggingface_hub>=0.23.0->huggingface_hub[cli]>=0.23.0->timesfm[torch]) (2.32.4)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/anaconda3/envs/timesfm311/lib/python3.11/site-packages (from huggingface_hub>=0.23.0->huggingface_hub[cli]>=0.23.0->timesfm[torch]) (4.67.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /opt/anaconda3/envs/timesfm311/lib/python3.11/site-packages (from huggingface_hub>=0.23.0->huggingface_hub[cli]>=0.23.0->timesfm[torch]) (1.1.7)\n",
      "Requirement already satisfied: InquirerPy==0.3.4 in /opt/anaconda3/envs/timesfm311/lib/python3.11/site-packages (from huggingface_hub[cli]>=0.23.0->timesfm[torch]) (0.3.4)\n",
      "Requirement already satisfied: pfzy<0.4.0,>=0.3.1 in /opt/anaconda3/envs/timesfm311/lib/python3.11/site-packages (from InquirerPy==0.3.4->huggingface_hub[cli]>=0.23.0->timesfm[torch]) (0.3.4)\n",
      "Requirement already satisfied: prompt-toolkit<4.0.0,>=3.0.1 in /opt/anaconda3/envs/timesfm311/lib/python3.11/site-packages (from InquirerPy==0.3.4->huggingface_hub[cli]>=0.23.0->timesfm[torch]) (3.0.51)\n",
      "Requirement already satisfied: wcwidth in /opt/anaconda3/envs/timesfm311/lib/python3.11/site-packages (from prompt-toolkit<4.0.0,>=3.0.1->InquirerPy==0.3.4->huggingface_hub[cli]>=0.23.0->timesfm[torch]) (0.2.13)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/envs/timesfm311/lib/python3.11/site-packages (from pandas>=2.0.0->timesfm[torch]) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/envs/timesfm311/lib/python3.11/site-packages (from pandas>=2.0.0->timesfm[torch]) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/envs/timesfm311/lib/python3.11/site-packages (from pandas>=2.0.0->timesfm[torch]) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/envs/timesfm311/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas>=2.0.0->timesfm[torch]) (1.17.0)\n",
      "Requirement already satisfied: scipy>=1.8.0 in /opt/anaconda3/envs/timesfm311/lib/python3.11/site-packages (from scikit-learn>=1.2.2->timesfm[torch]) (1.16.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/anaconda3/envs/timesfm311/lib/python3.11/site-packages (from scikit-learn>=1.2.2->timesfm[torch]) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/anaconda3/envs/timesfm311/lib/python3.11/site-packages (from scikit-learn>=1.2.2->timesfm[torch]) (3.6.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/envs/timesfm311/lib/python3.11/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "\u001b[33mWARNING: torch 2.8.0 does not provide the extra 'cuda'\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: click>=8.0.0 in /opt/anaconda3/envs/timesfm311/lib/python3.11/site-packages (from typer>=0.12.3->timesfm[torch]) (8.2.1)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /opt/anaconda3/envs/timesfm311/lib/python3.11/site-packages (from typer>=0.12.3->timesfm[torch]) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /opt/anaconda3/envs/timesfm311/lib/python3.11/site-packages (from typer>=0.12.3->timesfm[torch]) (14.1.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/anaconda3/envs/timesfm311/lib/python3.11/site-packages (from rich>=10.11.0->typer>=0.12.3->timesfm[torch]) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/anaconda3/envs/timesfm311/lib/python3.11/site-packages (from rich>=10.11.0->typer>=0.12.3->timesfm[torch]) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/anaconda3/envs/timesfm311/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer>=0.12.3->timesfm[torch]) (0.1.2)\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /opt/anaconda3/envs/timesfm311/lib/python3.11/site-packages (from wandb>=0.17.5->timesfm[torch]) (3.1.45)\n",
      "Requirement already satisfied: platformdirs in /opt/anaconda3/envs/timesfm311/lib/python3.11/site-packages (from wandb>=0.17.5->timesfm[torch]) (4.3.8)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in /opt/anaconda3/envs/timesfm311/lib/python3.11/site-packages (from wandb>=0.17.5->timesfm[torch]) (6.32.0)\n",
      "Requirement already satisfied: pydantic<3 in /opt/anaconda3/envs/timesfm311/lib/python3.11/site-packages (from wandb>=0.17.5->timesfm[torch]) (2.11.7)\n",
      "Requirement already satisfied: sentry-sdk>=2.0.0 in /opt/anaconda3/envs/timesfm311/lib/python3.11/site-packages (from wandb>=0.17.5->timesfm[torch]) (2.35.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/anaconda3/envs/timesfm311/lib/python3.11/site-packages (from pydantic<3->wandb>=0.17.5->timesfm[torch]) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /opt/anaconda3/envs/timesfm311/lib/python3.11/site-packages (from pydantic<3->wandb>=0.17.5->timesfm[torch]) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /opt/anaconda3/envs/timesfm311/lib/python3.11/site-packages (from pydantic<3->wandb>=0.17.5->timesfm[torch]) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/anaconda3/envs/timesfm311/lib/python3.11/site-packages (from requests->huggingface_hub>=0.23.0->huggingface_hub[cli]>=0.23.0->timesfm[torch]) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/envs/timesfm311/lib/python3.11/site-packages (from requests->huggingface_hub>=0.23.0->huggingface_hub[cli]>=0.23.0->timesfm[torch]) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/envs/timesfm311/lib/python3.11/site-packages (from requests->huggingface_hub>=0.23.0->huggingface_hub[cli]>=0.23.0->timesfm[torch]) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/envs/timesfm311/lib/python3.11/site-packages (from requests->huggingface_hub>=0.23.0->huggingface_hub[cli]>=0.23.0->timesfm[torch]) (2025.8.3)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/anaconda3/envs/timesfm311/lib/python3.11/site-packages (from gitpython!=3.1.29,>=1.0.0->wandb>=0.17.5->timesfm[torch]) (4.0.12)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /opt/anaconda3/envs/timesfm311/lib/python3.11/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb>=0.17.5->timesfm[torch]) (5.0.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/envs/timesfm311/lib/python3.11/site-packages (from jinja2->torch) (3.0.2)\n",
      "Using cached timesfm-1.3.0-py3-none-any.whl (55 kB)\n",
      "Installing collected packages: timesfm\n",
      "Successfully installed timesfm-1.3.0\n"
     ]
    }
   ],
   "source": [
    "!pip install \"timesfm[torch]\" torch --upgrade\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Device: cpu\n"
     ]
    }
   ],
   "source": [
    "# %% [1] Imports & Setup\n",
    "import os, re, glob, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import Ridge  # 보정용 (MultiOutput)\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "\n",
    "import torch\n",
    "import timesfm  # 설치됨 가정: pip install \"timesfm[torch]\"\n",
    "\n",
    "def set_seed(seed: int = 42):\n",
    "    random.seed(seed); np.random.seed(seed); torch.manual_seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed); torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "LOOKBACK, PREDICT = 28, 7\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "FREQ_FOR_DAILY = 0  # TimesFM freq index (일 단위)\n",
    "\n",
    "TRAIN_PATH = \"/Users/jeong-kyu/Documents/LG_Aimers_7기/open/train/train.csv\"\n",
    "TEST_GLOB = \"/Users/jeong-kyu/Documents/LG_Aimers_7기/open/test/TEST_*.csv\"\n",
    "SAMPLE_SUB_PATH = \"/Users/jeong-kyu/Documents/LG_Aimers_7기/open/sample_submission.csv\"\n",
    "OUT_PATH = \"/Users/jeong-kyu/Documents/LG_Aimers_7기/baseline_submission_timesfm_ft_like.csv\"\n",
    "\n",
    "print(f\"[INFO] Device: {DEVICE}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Load train: /Users/jeong-kyu/Documents/LG_Aimers_7기/open/train/train.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>영업일자</th>\n",
       "      <th>영업장명_메뉴명</th>\n",
       "      <th>매출수량</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>느티나무 셀프BBQ_1인 수저세트</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-01-02</td>\n",
       "      <td>느티나무 셀프BBQ_1인 수저세트</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-01-03</td>\n",
       "      <td>느티나무 셀프BBQ_1인 수저세트</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-01-04</td>\n",
       "      <td>느티나무 셀프BBQ_1인 수저세트</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-01-05</td>\n",
       "      <td>느티나무 셀프BBQ_1인 수저세트</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         영업일자            영업장명_메뉴명  매출수량\n",
       "0  2023-01-01  느티나무 셀프BBQ_1인 수저세트     0\n",
       "1  2023-01-02  느티나무 셀프BBQ_1인 수저세트     0\n",
       "2  2023-01-03  느티나무 셀프BBQ_1인 수저세트     0\n",
       "3  2023-01-04  느티나무 셀프BBQ_1인 수저세트     0\n",
       "4  2023-01-05  느티나무 셀프BBQ_1인 수저세트     0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %% [2] Load train\n",
    "print(f\"[INFO] Load train: {TRAIN_PATH}\")\n",
    "train = pd.read_csv(TRAIN_PATH)\n",
    "train.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 3 files: 100%|██████████| 3/3 [00:00<00:00, 55676.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loaded HF repo: google/timesfm-1.0-200m-pytorch\n"
     ]
    }
   ],
   "source": [
    "# %% [3] Load TimesFM pretrained\n",
    "HF_REPO = \"google/timesfm-1.0-200m-pytorch\"  # 필요시 2.0-500m로 교체 가능\n",
    "\n",
    "tfm_hparams = timesfm.TimesFmHparams(\n",
    "    backend=\"gpu\" if torch.cuda.is_available() else \"cpu\",\n",
    "    per_core_batch_size=32,\n",
    "    horizon_len=max(128, PREDICT),\n",
    "    context_len=512,  # v2.0이면 2048도 가능\n",
    ")\n",
    "\n",
    "tfm = timesfm.TimesFm(\n",
    "    hparams=tfm_hparams,\n",
    "    checkpoint=timesfm.TimesFmCheckpoint(huggingface_repo_id=HF_REPO),\n",
    ")\n",
    "print(f\"[INFO] Loaded HF repo: {HF_REPO}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preparing (scalers/last_seq): 100%|██████████| 193/193 [00:00<00:00, 1289.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Prepared series: 193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# %% [4] Prepare scalers & last sequences\n",
    "def prepare_timesfm(train_df: pd.DataFrame) -> dict:\n",
    "    prepared = {}\n",
    "    for store_menu, group in tqdm(train_df.groupby([\"영업장명_메뉴명\"]), desc=\"Preparing (scalers/last_seq)\"):\n",
    "        g = group.sort_values(\"영업일자\").copy()\n",
    "        if len(g) < LOOKBACK:\n",
    "            continue\n",
    "        scaler = MinMaxScaler()\n",
    "        scaled = scaler.fit_transform(g[[\"매출수량\"]].values.astype(float))\n",
    "        last_seq = scaled[-LOOKBACK:]  # (28,1)\n",
    "        prepared[store_menu] = {\"scaler\": scaler, \"last_sequence\": last_seq}\n",
    "    print(f\"[INFO] Prepared series: {len(prepared)}\")\n",
    "    return prepared\n",
    "\n",
    "prepared_cache = prepare_timesfm(train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building calibration pairs:   8%|▊         | 15/193 [38:13<7:33:31, 152.87s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[34]\u001b[39m\u001b[32m, line 58\u001b[39m\n\u001b[32m     55\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m np.concatenate(global_X, axis=\u001b[32m0\u001b[39m), np.concatenate(global_y, axis=\u001b[32m0\u001b[39m)\n\u001b[32m     57\u001b[39m \u001b[38;5;66;03m# 글로벌 보정기(권장) — 시리즈별로 하고 싶으면 use_per_series_model=True로 바꾸세요.\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m58\u001b[39m calib_X, calib_y = \u001b[43mbuild_calib_pairs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_per_series_model\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     59\u001b[39m calib_X.shape, calib_y.shape\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[34]\u001b[39m\u001b[32m, line 32\u001b[39m, in \u001b[36mbuild_calib_pairs\u001b[39m\u001b[34m(train_df, use_per_series_model)\u001b[39m\n\u001b[32m     29\u001b[39m y_seq = vals[i+LOOKBACK:i+LOOKBACK+PREDICT]    \u001b[38;5;66;03m# (7,)\u001b[39;00m\n\u001b[32m     31\u001b[39m \u001b[38;5;66;03m# TimesFM로 예측(포인트)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m pred, _ = \u001b[43mtfm\u001b[49m\u001b[43m.\u001b[49m\u001b[43mforecast\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx_seq\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfreq\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mFREQ_FOR_DAILY\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     33\u001b[39m pred = np.asarray(pred[\u001b[32m0\u001b[39m])[:PREDICT]           \u001b[38;5;66;03m# (7,)\u001b[39;00m\n\u001b[32m     35\u001b[39m X_list.append(pred)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/timesfm311/lib/python3.11/site-packages/timesfm/timesfm_base.py:395\u001b[39m, in \u001b[36mTimesFmBase.forecast\u001b[39m\u001b[34m(self, inputs, freq, window_size, forecast_context_len, return_forecast_on_context, normalize)\u001b[39m\n\u001b[32m    393\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m normalize:\n\u001b[32m    394\u001b[39m   inputs, stats = _normalize(inputs)\n\u001b[32m--> \u001b[39m\u001b[32m395\u001b[39m mean_forecast, quantile_forecast = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_forecast\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    396\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    397\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfreq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    398\u001b[39m \u001b[43m    \u001b[49m\u001b[43mwindow_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    399\u001b[39m \u001b[43m    \u001b[49m\u001b[43mforecast_context_len\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    400\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_forecast_on_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    401\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    402\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m stats \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    403\u001b[39m   stats = np.array(stats)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/timesfm311/lib/python3.11/site-packages/timesfm/timesfm_torch.py:136\u001b[39m, in \u001b[36mTimesFmTorch._forecast\u001b[39m\u001b[34m(self, inputs, freq, window_size, forecast_context_len, return_forecast_on_context)\u001b[39m\n\u001b[32m    129\u001b[39m t_input_padding = torch.Tensor(\n\u001b[32m    130\u001b[39m     input_padding[i * \u001b[38;5;28mself\u001b[39m.global_batch_size:(i + \u001b[32m1\u001b[39m) *\n\u001b[32m    131\u001b[39m                   \u001b[38;5;28mself\u001b[39m.global_batch_size]).to(\u001b[38;5;28mself\u001b[39m._device)\n\u001b[32m    132\u001b[39m t_inp_freq = torch.LongTensor(\n\u001b[32m    133\u001b[39m     inp_freq[i * \u001b[38;5;28mself\u001b[39m.global_batch_size:(i + \u001b[32m1\u001b[39m) *\n\u001b[32m    134\u001b[39m              \u001b[38;5;28mself\u001b[39m.global_batch_size, :]).to(\u001b[38;5;28mself\u001b[39m._device)\n\u001b[32m--> \u001b[39m\u001b[32m136\u001b[39m mean_output, full_output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    137\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_ts\u001b[49m\u001b[43m=\u001b[49m\u001b[43mt_input_ts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    138\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpaddings\u001b[49m\u001b[43m=\u001b[49m\u001b[43mt_input_padding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    139\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfreq\u001b[49m\u001b[43m=\u001b[49m\u001b[43mt_inp_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    140\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhorizon_len\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mhorizon_len\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    141\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_patch_len\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moutput_patch_len\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    142\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Returns forecasts on context for parity with the Jax version.\u001b[39;49;00m\n\u001b[32m    143\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_forecast_on_context\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    144\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    145\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m return_forecast_on_context:\n\u001b[32m    146\u001b[39m   mean_output = mean_output[:, \u001b[38;5;28mself\u001b[39m._horizon_start:, ...]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/timesfm311/lib/python3.11/site-packages/timesfm/pytorch_patched_decoder.py:774\u001b[39m, in \u001b[36mPatchedTimeSeriesDecoder.decode\u001b[39m\u001b[34m(self, input_ts, paddings, freq, horizon_len, output_patch_len, max_len, return_forecast_on_context)\u001b[39m\n\u001b[32m    772\u001b[39m input_ts = final_out[:, -max_len:]\n\u001b[32m    773\u001b[39m input_padding = current_padding[:, -max_len:]\n\u001b[32m--> \u001b[39m\u001b[32m774\u001b[39m fprop_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43minput_ts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_padding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    775\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m return_forecast_on_context \u001b[38;5;129;01mand\u001b[39;00m step_index == \u001b[32m0\u001b[39m:\n\u001b[32m    776\u001b[39m   \u001b[38;5;66;03m# For the first decodings step, collect the model forecast on the\u001b[39;00m\n\u001b[32m    777\u001b[39m   \u001b[38;5;66;03m# context except the unavailable first input batch forecast.\u001b[39;00m\n\u001b[32m    778\u001b[39m   new_full_ts = fprop_outputs[:, \u001b[32m0\u001b[39m:-\u001b[32m1\u001b[39m, \u001b[32m0\u001b[39m:\u001b[38;5;28mself\u001b[39m.config.patch_len, :]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/timesfm311/lib/python3.11/site-packages/torch/nn/modules/module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/timesfm311/lib/python3.11/site-packages/torch/nn/modules/module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/timesfm311/lib/python3.11/site-packages/timesfm/pytorch_patched_decoder.py:721\u001b[39m, in \u001b[36mPatchedTimeSeriesDecoder.forward\u001b[39m\u001b[34m(self, input_ts, input_padding, freq)\u001b[39m\n\u001b[32m    719\u001b[39m f_emb = \u001b[38;5;28mself\u001b[39m.freq_emb(freq)  \u001b[38;5;66;03m# B x 1 x D\u001b[39;00m\n\u001b[32m    720\u001b[39m model_input += f_emb\n\u001b[32m--> \u001b[39m\u001b[32m721\u001b[39m model_output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstacked_transformer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpatched_padding\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    723\u001b[39m output_ts = \u001b[38;5;28mself\u001b[39m._postprocess_output(model_output, num_outputs, stats)\n\u001b[32m    724\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output_ts\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/timesfm311/lib/python3.11/site-packages/torch/nn/modules/module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/timesfm311/lib/python3.11/site-packages/torch/nn/modules/module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/timesfm311/lib/python3.11/site-packages/timesfm/pytorch_patched_decoder.py:518\u001b[39m, in \u001b[36mStackedDecoder.forward\u001b[39m\u001b[34m(self, hidden_states, paddings, kv_write_indices, kv_caches)\u001b[39m\n\u001b[32m    516\u001b[39m   layer = \u001b[38;5;28mself\u001b[39m.layers[i]\n\u001b[32m    517\u001b[39m   kv_cache = kv_caches[i] \u001b[38;5;28;01mif\u001b[39;00m kv_caches \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m518\u001b[39m   _, hidden_states = \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    519\u001b[39m \u001b[43m      \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    520\u001b[39m \u001b[43m      \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    521\u001b[39m \u001b[43m      \u001b[49m\u001b[43mpaddings\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpaddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    522\u001b[39m \u001b[43m      \u001b[49m\u001b[43mkv_write_indices\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkv_write_indices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    523\u001b[39m \u001b[43m      \u001b[49m\u001b[43mkv_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkv_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    524\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    525\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m hidden_states\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/timesfm311/lib/python3.11/site-packages/torch/nn/modules/module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/timesfm311/lib/python3.11/site-packages/torch/nn/modules/module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/timesfm311/lib/python3.11/site-packages/timesfm/pytorch_patched_decoder.py:464\u001b[39m, in \u001b[36mTimesFMDecoderLayer.forward\u001b[39m\u001b[34m(self, hidden_states, mask, paddings, kv_write_indices, kv_cache)\u001b[39m\n\u001b[32m    462\u001b[39m residual = hidden_states\n\u001b[32m    463\u001b[39m hidden_states = \u001b[38;5;28mself\u001b[39m.input_layernorm(hidden_states)\n\u001b[32m--> \u001b[39m\u001b[32m464\u001b[39m scores, hidden_states = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mself_attn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    465\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    466\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    467\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkv_write_indices\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkv_write_indices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    468\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkv_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkv_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    469\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    470\u001b[39m hidden_states = residual + hidden_states\n\u001b[32m    472\u001b[39m \u001b[38;5;66;03m# MLP\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/timesfm311/lib/python3.11/site-packages/torch/nn/modules/module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/timesfm311/lib/python3.11/site-packages/torch/nn/modules/module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/timesfm311/lib/python3.11/site-packages/timesfm/pytorch_patched_decoder.py:382\u001b[39m, in \u001b[36mTimesFMAttention.forward\u001b[39m\u001b[34m(self, hidden_states, mask, kv_write_indices, kv_cache)\u001b[39m\n\u001b[32m    378\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(hidden_states_shape) == \u001b[32m3\u001b[39m\n\u001b[32m    380\u001b[39m batch_size, input_len, _ = hidden_states_shape\n\u001b[32m--> \u001b[39m\u001b[32m382\u001b[39m qkv = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mqkv_proj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    383\u001b[39m xq, xk, xv = qkv.split([\u001b[38;5;28mself\u001b[39m.q_size, \u001b[38;5;28mself\u001b[39m.kv_size, \u001b[38;5;28mself\u001b[39m.kv_size], dim=-\u001b[32m1\u001b[39m)\n\u001b[32m    385\u001b[39m xq = xq.view(batch_size, -\u001b[32m1\u001b[39m, \u001b[38;5;28mself\u001b[39m.num_heads, \u001b[38;5;28mself\u001b[39m.head_dim)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/timesfm311/lib/python3.11/site-packages/torch/nn/modules/module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/timesfm311/lib/python3.11/site-packages/torch/nn/modules/module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/timesfm311/lib/python3.11/site-packages/torch/nn/modules/linear.py:125\u001b[39m, in \u001b[36mLinear.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    124\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m125\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# %% [5] Build calibration (fine-tuning-like) dataset\n",
    "def build_calib_pairs(train_df: pd.DataFrame,\n",
    "                      use_per_series_model: bool = False):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "      if use_per_series_model:\n",
    "        dict[series_key] = { 'X': np.ndarray[n_samples, PREDICT], 'y': np.ndarray[n_samples, PREDICT] }\n",
    "      else:\n",
    "        global_X, global_y\n",
    "    \"\"\"\n",
    "    if use_per_series_model:\n",
    "        out = {}\n",
    "\n",
    "    global_X, global_y = [], []\n",
    "\n",
    "    for key, group in tqdm(train_df.groupby([\"영업장명_메뉴명\"]), desc=\"Building calibration pairs\"):\n",
    "        g = group.sort_values(\"영업일자\").copy()\n",
    "        if len(g) < LOOKBACK + PREDICT:\n",
    "            continue\n",
    "\n",
    "        # 시리즈별 스케일러 (예측/학습 일관성)\n",
    "        scaler = MinMaxScaler()\n",
    "        vals = scaler.fit_transform(g[[\"매출수량\"]].values.astype(float)).reshape(-1)\n",
    "\n",
    "        X_list, y_list = [], []\n",
    "        # 슬라이딩: lookback을 입력, 이후 predict 길이를 타깃\n",
    "        for i in range(len(vals) - LOOKBACK - PREDICT + 1):\n",
    "            x_seq = vals[i:i+LOOKBACK]                     # (28,)\n",
    "            y_seq = vals[i+LOOKBACK:i+LOOKBACK+PREDICT]    # (7,)\n",
    "\n",
    "            # TimesFM로 예측(포인트)\n",
    "            pred, _ = tfm.forecast([x_seq], freq=[FREQ_FOR_DAILY])\n",
    "            pred = np.asarray(pred[0])[:PREDICT]           # (7,)\n",
    "\n",
    "            X_list.append(pred)\n",
    "            y_list.append(y_seq)\n",
    "\n",
    "        if not X_list:\n",
    "            continue\n",
    "\n",
    "        X_arr = np.stack(X_list, axis=0)\n",
    "        y_arr = np.stack(y_list, axis=0)\n",
    "\n",
    "        if use_per_series_model:\n",
    "            out[key] = {\"X\": X_arr, \"y\": y_arr}\n",
    "        else:\n",
    "            global_X.append(X_arr)\n",
    "            global_y.append(y_arr)\n",
    "\n",
    "    if use_per_series_model:\n",
    "        return out\n",
    "    else:\n",
    "        if not global_X:\n",
    "            raise RuntimeError(\"No calibration pairs built. Check train length.\")\n",
    "        return np.concatenate(global_X, axis=0), np.concatenate(global_y, axis=0)\n",
    "\n",
    "# 글로벌 보정기(권장) — 시리즈별로 하고 싶으면 use_per_series_model=True로 바꾸세요.\n",
    "calib_X, calib_y = build_calib_pairs(train, use_per_series_model=False)\n",
    "calib_X.shape, calib_y.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [6] Train calibration model (multi-output Ridge)\n",
    "calibrator = MultiOutputRegressor(Ridge(alpha=1.0, fit_intercept=True, random_state=42))\n",
    "calibrator.fit(calib_X, calib_y)\n",
    "print(\"[INFO] Calibrator trained (global)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [7] Predict function with calibration\n",
    "def predict_timesfm_with_calib(test_df: pd.DataFrame,\n",
    "                               prepared: dict,\n",
    "                               test_prefix: str,\n",
    "                               use_per_series_model: bool = False,\n",
    "                               per_series_calibrators: dict | None = None,\n",
    "                               global_calibrator: MultiOutputRegressor | None = None):\n",
    "    results = []\n",
    "    skipped = 0\n",
    "\n",
    "    for key, g in test_df.groupby([\"영업장명_메뉴명\"]):\n",
    "        if key not in prepared:\n",
    "            skipped += 1\n",
    "            continue\n",
    "\n",
    "        scaler = prepared[key][\"scaler\"]\n",
    "        last_seq_train = prepared[key][\"last_sequence\"].reshape(-1)  # (28,)\n",
    "\n",
    "        g = g.sort_values(\"영업일자\")\n",
    "        recent = g[\"매출수량\"].values.astype(float)[-LOOKBACK:]\n",
    "\n",
    "        if len(recent) < LOOKBACK:\n",
    "            x_scaled = last_seq_train\n",
    "        else:\n",
    "            x_scaled = scaler.transform(recent.reshape(-1,1)).reshape(-1)\n",
    "\n",
    "        # TimesFM 포인트 예측\n",
    "        pred, _ = tfm.forecast([x_scaled], freq=[FREQ_FOR_DAILY])\n",
    "        pred = np.asarray(pred[0])[:PREDICT].reshape(1, -1)  # (1,7)\n",
    "\n",
    "        # 보정 적용\n",
    "        if use_per_series_model and per_series_calibrators is not None and key in per_series_calibrators:\n",
    "            pred_corr = per_series_calibrators[key].predict(pred)[0]\n",
    "        else:\n",
    "            pred_corr = global_calibrator.predict(pred)[0]\n",
    "\n",
    "        # 역스케일 + 음수 컷\n",
    "        restored = []\n",
    "        for v in pred_corr:\n",
    "            restored_val = scaler.inverse_transform(np.array([[v]]) )[0, 0]\n",
    "            restored.append(max(restored_val, 0.0))\n",
    "\n",
    "        dates = [f\"{test_prefix}+{i+1}일\" for i in range(PREDICT)]\n",
    "        for d, val in zip(dates, restored):\n",
    "            results.append({\"영업일자\": d, \"영업장명_메뉴명\": key, \"매출수량\": val})\n",
    "\n",
    "    if skipped:\n",
    "        print(f\"[WARN] train에 없던 키 {skipped}개 스킵됨\")\n",
    "    return pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [8] Predict over all test files\n",
    "all_preds = []\n",
    "test_files = sorted(glob.glob(TEST_GLOB))\n",
    "print(f\"[INFO] Found test files: {len(test_files)}\")\n",
    "\n",
    "for path in test_files:\n",
    "    if os.path.isdir(path):\n",
    "        continue\n",
    "    test_df = pd.read_csv(path)\n",
    "    filename = os.path.basename(path)\n",
    "    m = re.search(r\"(TEST_\\d+)\", filename)\n",
    "    if not m:\n",
    "        print(f\"[WARN] prefix not found: {filename}\")\n",
    "        continue\n",
    "    test_prefix = m.group(1)\n",
    "\n",
    "    pred_df = predict_timesfm_with_calib(\n",
    "        test_df,\n",
    "        prepared=prepared_cache,\n",
    "        test_prefix=test_prefix,\n",
    "        use_per_series_model=False,\n",
    "        per_series_calibrators=None,\n",
    "        global_calibrator=calibrator,\n",
    "    )\n",
    "    if not pred_df.empty:\n",
    "        all_preds.append(pred_df)\n",
    "\n",
    "if not all_preds:\n",
    "    raise RuntimeError(\"[ERROR] 예측 결과가 비었습니다.\")\n",
    "\n",
    "full_pred_df = pd.concat(all_preds, ignore_index=True)\n",
    "full_pred_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [9] Convert to submission & save\n",
    "def convert_to_submission_format(pred_df: pd.DataFrame, sample_submission: pd.DataFrame):\n",
    "    final_df = sample_submission.copy()\n",
    "    pred_df = pred_df.copy()\n",
    "    pred_df['영업장명_메뉴명'] = pred_df['영업장명_메뉴명'].apply(\n",
    "        lambda x: (x[0] if isinstance(x, (list, tuple)) else x)\n",
    "    ).astype(str).str.strip()\n",
    "    pred_df['영업일자'] = pred_df['영업일자'].astype(str).str.strip()\n",
    "\n",
    "    pred_agg = (pred_df\n",
    "                .groupby(['영업일자', '영업장명_메뉴명'], as_index=True)['매출수량']\n",
    "                .sum())\n",
    "    pred_wide = pred_agg.unstack(fill_value=0)\n",
    "\n",
    "    id_col = final_df.columns[0]\n",
    "    final_df[id_col] = final_df[id_col].astype(str)\n",
    "    dates = final_df[id_col].tolist()\n",
    "\n",
    "    sample_cols = list(final_df.columns[1:])\n",
    "    sample_col_norm_map = {col: str(col).strip() for col in sample_cols}\n",
    "\n",
    "    pred_wide = pred_wide.reindex(dates)\n",
    "    fill_vals = {}\n",
    "    for raw_col in sample_cols:\n",
    "        norm_col = sample_col_norm_map[raw_col]\n",
    "        if (pred_wide is not None) and (norm_col in pred_wide.columns):\n",
    "            fill_vals[raw_col] = pred_wide[norm_col].to_numpy()\n",
    "        else:\n",
    "            fill_vals[raw_col] = np.zeros(len(dates), dtype=float)\n",
    "\n",
    "    for raw_col, arr in fill_vals.items():\n",
    "        final_df[raw_col] = arr\n",
    "\n",
    "    return final_df\n",
    "\n",
    "sample_submission = pd.read_csv(SAMPLE_SUB_PATH)\n",
    "submission = convert_to_submission_format(full_pred_df, sample_submission)\n",
    "submission.to_csv(OUT_PATH, index=False, encoding=\"utf-8-sig\")\n",
    "print(f\"[INFO] Saved: {OUT_PATH}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "timesfm311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
